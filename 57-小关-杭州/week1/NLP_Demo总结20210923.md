

## 对Demo处理流程的理解？

Demo实现的功能：判断文本中是否有特定字符出现

步骤：

1. 通过建立字表生成样本，并打上标签，包含特定字符的样本为正样本，记为“1”，反之，不包含特定字符的样本为负样本，记为“0”，代码如下：

   ```python
   # 建立字表
   def build_vocab():
       chars = "abcdefghijklmnopqrstuvwxyz"  # 字符集
       vocab = {}
       for index, char in enumerate(chars):
           vocab[char] = index + 1   # 每个字对应一个序号
       vocab['unk'] = len(vocab)+1
       return vocab
   vocab = build_vocab()
   print(vocab, type(vocab))  # {'a': 1, 'b': 2, 'c': 3, 'd': 4, 'e': 5, 'f': 6, 'g': 7, 'h': 8, 'i': 9, 'j': 10, 'k': 11, 'l': 12, 'm': 13, 'n': 14, 'o': 15, 'p': 16, 'q': 17, 'r': 18, 's': 19, 't': 20, 'u': 21, 'v': 22, 'w': 23, 'x': 24, 'y': 25, 'z': 26, 'unk': 27} <class 'dict'>
   ```

   字母“a”~“z”分别被赋予“1”~“26”，其中，26个英文字母之外的输入均被记为“unk”，赋予键值“27”。

   ```python
   import random
   def build_sample(vocab, sentence_length):
       # 随机从字表选取文本长度为sentence_length个字，可能重复
       x = [random.choice(list(vocab.keys())) for _ in range(sentence_length)]
       # 若句子中包含“a”或“b”或“c”时，为正样本
       if set("abc") & set(x):
           y = 1
       # 指定字都未出现，则为负样本
       else:
           y = 0
       x = [vocab.get(word, vocab['unk']) for word in x]   # 将字转换成序号，为了做embedding
       return x, y
   vocab = build_vocab()
   sample = build_sample(vocab, 5)
   print(sample, type(sample))  # ([27, 11, 13, 25, 10], 0) <class 'tuple'>
   ```

   ```python
   # get()函数的作用
   # 返回字典中指定键的值
   # 语法：dict.get(key, default=None)
   # key--字典中要查找的键
   # default--如果指定键的值不存在，则返回该默认值
   x = 'apple'
   x = [vocab.get(word, vocab['unk']) for word in x]
   print(x)  # [1, 16, 16, 12, 5]
   
   x = 'apple13'
   x = [vocab.get(word, vocab['unk']) for word in x]
   print(x)  # [1, 16, 16, 12, 5, 27, 27]
   ```

   生成一定数量的样本即可构成数据集dataset。

2. 构建神经网络

   Pytorch中提供了`nn`神经网络模块，构建神经网络需要用到`nn.Module`中的方法，因此，新声明的类需要继承父类`nn.Module`。

   通过Embedding将建立的字表vocab映射为向量，可简单理解为赋予vocab中每个字符（以值表示）更加丰富的特征，作为网络的输入。

   层是网络模型中的基本功能单元，一般的RNN网络模型可以分为线性层（`nn.Linear`）、池化层（比如`nn.AvgPool1d`）、全连接层（实际也为线性层）等，除此之外，为了使得使用梯度反向更新参数，需要引入激活函数、Dropout等技术并设计合理的损失函数。

   网络模型中需要包含前向过程，即输入数据的流向。

   ```python
   class TorchModel(nn.Module):
       def __init__(self, input_dim, sentence_length, vocab):
           super(TorchModel, self).__init__()
           self.embedding = nn.Embedding(len(vocab) + 1, input_dim)
           self.layer = nn.Linear(input_dim, input_dim)
           self.pool = nn.AvgPool1d(sentence_length)
           self.classify = nn.Linear(input_dim, 1)
           self.activation = torch.sigmoid     # sigmoid做激活函数
           self.dropout = nn.Dropout(0.1)
           self.loss = nn.functional.mse_loss  # loss采用均方差损失
   
       # 当输入真实标签，返回loss值；无真实标签，返回预测值
       def forward(self, x, y=None):
           x = self.embedding(x)  # input shape:(batch_size, sen_len)
           x = self.layer(x)      # input shape:(batch_size, sen_len, input_dim)
           x = self.dropout(x)    # input shape:(batch_size, sen_len, input_dim)
           x = self.activation(x)  # input shape:(batch_size, sen_len, input_dim)
           x = self.pool(x.transpose(1, 2)).squeeze()  # input shape:(batch_size, sen_len, input_dim)
           x = self.classify(x)   # input shape:(batch_size, input_dim)
           y_pred = self.activation(x)               # input shape:(batch_size, 1)
           if y is not None:
               return self.loss(y_pred, y)
           else:
               return y_pred
   ```

3. 训练神经网络模型

   - 一般采用分批训练的方式，即在多个epoch中训练一定的长度的batch。

   - 梯度更新所用到的优化器在`torch.optim`中，包含`Adam`、`SGD`等。

     ```python
     # 在epoch下分批训练batch
     for epoch in range(epoch_num):
         model.train()
         watch_loss = []
         for batch in range(int(train_sample / batch_size)):
             x, y = build_dataset(batch_size, vocab, sentence_length) # 构建一组训练样本
             optim.zero_grad()    # 梯度归零
             loss = model(x, y)   # 计算loss
             loss.backward()      # 计算梯度
             optim.step()         # 更新权重
             watch_loss.append(loss.item())
     ```

4. 评估神经网络模型的性能

   通常，将数据集分为训练集和测试集，训练集用于得到模型，而测试集用于评估模型的性能。

   ```python
   def evaluate(model, vocab, sample_length):
       model.eval()
       x, y = build_dataset(200, vocab, sample_length)   # 建立200个用于测试的样本
       print("本次预测集中共有%d个正样本，%d个负样本" % (sum(y), 200 - sum(y)))
       correct, wrong = 0, 0
       with torch.no_grad():
           y_pred = model(x)      # 模型预测
           for y_p, y_t in zip(y_pred, y):  # 与真实标签进行对比
               if float(y_p) < 0.5 and int(y_t) == 0:
                   correct += 1   # 负样本判断正确
               elif float(y_p) >= 0.5 and int(y_t) == 1:
                   correct += 1   # 正样本判断正确
               else:
                   wrong += 1
       print("正确预测个数：%d, 正确率：%f" % (correct, correct/(correct+wrong)))
       return correct/(correct+wrong)
   
   ```

   通过观察acc曲线和loss曲线，可以大致判断，模型在那个epoch上收敛，获得稳定性能。

   ![myplot](D:\_Gx\AI\badou_class\badouai-tujiban\57-小关-杭州\week1\fig\myplot.png)

5. 预测给定strings的结果

   获得性能稳定的模型之后，便可应用模型预测未知strings。

   ```python
   def predict(model_path, vocab_path, input_strings):
       char_dim = 20  # 每个字的维度
       sentence_length = 6  # 样本文本长度
       vocab = json.load(open(vocab_path, "r", encoding="utf8"))
       model = build_model(vocab, char_dim, sentence_length)    # 建立模型
       model.load_state_dict(torch.load(model_path))       # 加载训练好的权重
       x = []
       for input_string in input_strings:
           x.append([vocab[char] for char in input_string])  # 将输入序列化
       model.eval()   # 测试模式，不使用dropout
       with torch.no_grad():  # 不计算梯度
           result = model.forward(torch.LongTensor(x))  # 模型预测
       for i, input_string in enumerate(input_strings):
           print(round(float(result[i])), input_string, result[i])  # 打印结果
   ```

   预测test_strings中的字符串，是否包含“a”或“b”或“c”。

   ```python
   if __name__ == "__main__":
       main()
       test_strings = ["abvxee", "casdfg", "rqweqg", "nlkdww"]
       predict("model.pth", "vocab.json", test_strings)
   # 1 abvxee tensor([0.9434])
   # 1 casdfg tensor([0.9514])
   # 0 rqweqg tensor([0.1353])
   # 0 nlkdww tensor([0.1338])
   ```

   “abvxee”和“casdfg”中分别包含“a”和“c”，因此，模型的预测概率较高，将其判断为正样本；“rqweqg”和“nlkdww”中不包含“abc“，因此，模型将其判断为负样本。

## 修改正样本生成条件，完成训练和预测

（1）指定包含”s“的字符串为正样本

```python
if set("s") & set(x):
    y = 1
```

![myplot2](D:\_Gx\AI\badou_class\badouai-tujiban\57-小关-杭州\week1\fig\myplot2.png)

```python
# 预测结果
# 0 abvxee tensor([0.1331])
# 1 casdfg tensor([0.5528])
# 0 rqweqg tensor([0.1400])
# 0 nlkdww tensor([0.1269])
```

（2）指定包含”s“或”o“的字符串为正样本

```python
if set("so") & set(x):
    y = 1
```

![myplot3](D:\_Gx\AI\badou_class\badouai-tujiban\57-小关-杭州\week1\fig\myplot3.png)

```python
# 预测结果
# 0 abvxee tensor([0.1322])
# 1 casdfg tensor([0.5964])
# 0 rqweqg tensor([0.1184])
# 1 nlkdow tensor([0.6037])
```

（3）指定包含”s“或”o“或“w”或”z“的字符串为正样本

```python
if set("sowz") & set(x):
    y = 1
```

![myplot4](D:\_Gx\AI\badou_class\badouai-tujiban\57-小关-杭州\week1\fig\myplot4.png)

```python
# 预测结果
# 0 abvxee tensor([0.1337])
# 1 casdfg tensor([0.7044])
# 1 rqweqg tensor([0.7187])
# 1 nlkdow tensor([0.9762])
```



## 对Embedding的理解？

